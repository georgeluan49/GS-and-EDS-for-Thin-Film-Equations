{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254727e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268733f",
   "metadata": {},
   "source": [
    "## Auxillary function declarations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c95223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2026-01-01 23:45:49,526:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M5\n",
      "\n",
      "systemMemory: 24.00 GB\n",
      "maxCacheSize: 8.88 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1767339949.526939  210110 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1767339949.536715  210110 service.cc:145] XLA service 0xc49c34d00 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1767339949.536806  210110 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1767339949.537882  210110 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1767339949.537888  210110 mps_client.cc:384] XLA backend will use up to 19069206528 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "cpu = jax.devices(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38845249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, x_0, rtol=1e-8, atol=1e-9, max_iter=50, curr_step=0, prev_min=0):\n",
    "    \"\"\"\n",
    "    Multivariate Newton method with relative error control.\n",
    "    \"\"\"\n",
    "    x = x_0\n",
    "    f_jac = jax.jacobian(f)\n",
    "\n",
    "    def newton_step(x):\n",
    "        Fx = f(x)\n",
    "        J  = f_jac(x)\n",
    "        dx = jnp.linalg.solve(J, Fx)\n",
    "        return x - dx, dx, Fx\n",
    "\n",
    "    newton_step = jax.jit(newton_step, device=cpu)\n",
    "\n",
    "    for n in range(1, max_iter + 1):\n",
    "        x_new, dx, Fx = newton_step(x)\n",
    "\n",
    "        step_norm = jnp.linalg.norm(dx, ord=float('inf'))\n",
    "        x_norm    = jnp.linalg.norm(x, ord=float('inf'))\n",
    "        res_norm  = jnp.linalg.norm(Fx, ord=float('inf'))\n",
    "\n",
    "        #print(\n",
    "        #    f\"iter {n}: \"\n",
    "        #    f\"step = {step_norm:.3e}, \"\n",
    "        #    f\"residual = {res_norm:.3e}\"\n",
    "        #)\n",
    "\n",
    "        # Step-based criterion\n",
    "        step_ok = step_norm <= atol + rtol * max(1.0, x_norm)\n",
    "\n",
    "        # Residual-based criterion\n",
    "        res_ok = res_norm <= atol + rtol * jnp.linalg.norm(f(x_0), ord=float('inf'))\n",
    "\n",
    "        if step_ok and res_ok:\n",
    "            return x_new\n",
    "\n",
    "        x = x_new\n",
    "\n",
    "\n",
    "    raise RuntimeError(f\"Max iteration reached without convergence at Timestep: {curr_step}, with the minimum h at the previous step: {prev_min}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d60d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- flux components ---\n",
    "def h_xxx(h, dx):\n",
    "    \"\"\"Third derivative (periodic)\"\"\"\n",
    "    return (\n",
    "        jnp.roll(h, -1)\n",
    "        - 3.0 * h\n",
    "        + 3.0 * jnp.roll(h, 1)\n",
    "        - jnp.roll(h, 2)\n",
    "    ) / dx**3\n",
    "\n",
    "\n",
    "def f(h, eps):\n",
    "    h = jnp.maximum(h, 0.0)\n",
    "    h35 = h**3 * jnp.sqrt(h)   \n",
    "    return h**4 / (eps + h35)\n",
    "\n",
    "\n",
    "def a_gs(s1, s2, eps):\n",
    "    s = 0.5 * (s1 + s2)\n",
    "    return f(s, eps)\n",
    "\n",
    "\n",
    "def da_gs(s1, s2, eps):\n",
    "    s = jnp.maximum(s1 + s2, 0.0)\n",
    "    s35 = s**3 * jnp.sqrt(s)\n",
    "    num = 0.5 * s**3 * (4.0 * eps + 0.5 * s35)\n",
    "    den = (eps + s35)**2\n",
    "    return num / den\n",
    "\n",
    "\n",
    "\n",
    "def a_eds(s1, s2, eps):\n",
    "    h1 = jnp.maximum(s1, 0.0)\n",
    "    h2 = jnp.maximum(s2, 0.0)\n",
    "\n",
    "    Gp1 = 2.0 * jnp.sqrt(h1) - eps / (3.0 * h1**3)\n",
    "    Gp2 = 2.0 * jnp.sqrt(h2) - eps / (3.0 * h2**3)\n",
    "\n",
    "    num = h1 - h2\n",
    "    den = Gp1 - Gp2\n",
    "\n",
    "    # fallback when h1 ~ h2\n",
    "    a_diag = f(h1, eps)\n",
    "\n",
    "    return jnp.where(jnp.abs(den) > 1e-14, num / den, a_diag)\n",
    "\n",
    "\n",
    "# --- Diff schemes ---\n",
    "\n",
    "@jax.jit\n",
    "def GS(h, h_curr, dx, dt, eps):\n",
    "    h_f1 = jnp.roll(h, -1)\n",
    "    h_b1 = jnp.roll(h, 1)\n",
    "\n",
    "    f_f12 = a_gs(h, h_f1, eps) * h_xxx(h_f1, dx)\n",
    "    f_b12 = a_gs(h_b1, h, eps) * h_xxx(h, dx)\n",
    "\n",
    "    return h - h_curr + (dt / dx) * (f_f12 - f_b12)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def EDS(h, h_curr, dx, dt, eps):\n",
    "    h_f1 = jnp.roll(h, -1)\n",
    "    h_b1 = jnp.roll(h, 1)\n",
    "\n",
    "    f_f12 = a_eds(h,    h_f1, eps) * h_xxx(h_f1, dx)\n",
    "    f_b12 = a_eds(h_b1, h,    eps) * h_xxx(h,    dx)\n",
    "\n",
    "    return h - h_curr + (dt / dx) * (f_f12 - f_b12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09da27",
   "metadata": {},
   "source": [
    "## Coarse-grid simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec06eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "dx = float(2/N)\n",
    "dt = float(1e-7)\n",
    "eps = float(1e-14)\n",
    "\n",
    "x_coarse = jnp.linspace(-1.0, 1.0, N, endpoint=False, dtype=jnp.float64, device=cpu)\n",
    "\n",
    "h0_coarse = 0.8 - jnp.cos(jnp.pi * x_coarse) + 0.25 * jnp.cos(2 * jnp.pi * x_coarse)\n",
    "\n",
    "# Need to make sure h0_coarse lives on cpu\n",
    "h0_coarse = jax.device_put(h0_coarse, cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80594ffb",
   "metadata": {},
   "source": [
    "### Solution evolution using the generic scheme with large $\\Delta x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10000\n",
    "h_curr = h0_coarse\n",
    "\n",
    "h_min = jnp.min(jnp.abs(h_curr))\n",
    "\n",
    "sampled_iters = jnp.array([9, 99, 999, 9999])\n",
    "\n",
    "h_sampled = []\n",
    "\n",
    "for k in range(K):\n",
    "\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"Iter {k}\")\n",
    "\n",
    "\n",
    "    F = lambda h: GS(h, h_curr, dx, dt, eps)\n",
    "\n",
    "    h_next = newton(F, h_curr, rtol=1e-8, atol=2e-10, max_iter=50, curr_step=k+1, prev_min=h_min)\n",
    "\n",
    "    h_min = jnp.min(jnp.abs(h_curr))\n",
    "    h_curr = h_next\n",
    "\n",
    "    if k in sampled_iters:\n",
    "        h_sampled.append(h_curr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_coarse, h0_coarse, label=\"t = 0\")\n",
    "plt.plot(x_coarse, h_sampled[0], label=\"t = 1e-6\")\n",
    "plt.plot(x_coarse, h_sampled[1], label=\"t = 1e-5\")\n",
    "plt.plot(x_coarse, h_curr, label=\"t = 4.92e-5\")\n",
    "#plt.plot(x_coarse, h_sampled[2], label=\"t = 1e-4\")\n",
    "#plt.plot(x_coarse, h_sampled[3], label=\"t = 1e-3\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$h_\\epsilon(x, t), \\ \\epsilon=10^{-11}$\")\n",
    "#plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.savefig(\"sim_results_generic_coarse.png\", dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_coarse[495:530], h_curr[495:530])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e2fdd",
   "metadata": {},
   "source": [
    "### Solution evolution using the entropy-dissipating scheme with large $\\Delta x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10000\n",
    "h_curr = h0_coarse\n",
    "\n",
    "h_min = jnp.min(jnp.abs(h_curr))\n",
    "\n",
    "sampled_iters = jnp.array([9, 99, 999, 9999])\n",
    "\n",
    "h_sampled = []\n",
    "\n",
    "for k in range(K):\n",
    "\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"Iter {k}\")\n",
    "\n",
    "\n",
    "    F = lambda h: EDS(h, h_curr, dx, dt, eps)\n",
    "\n",
    "    h_next = newton(F, h_curr, rtol=1e-8, atol=1e-10, curr_step=k+1, prev_min=h_min)\n",
    "\n",
    "    h_min = jnp.min(jnp.abs(h_curr))\n",
    "    h_curr = h_next\n",
    "\n",
    "    if k in sampled_iters:\n",
    "        h_sampled.append(h_curr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68334042",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_coarse[128:140], h_curr[128:140])\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$h_{\\epsilon}(x, 0.001), \\ \\epsilon = 10^{-14}$\")\n",
    "plt.title(\"Coarse grid computation using EDS\")\n",
    "plt.ylim(0.0, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_coarse, h0_coarse, label=\"t = 0\")\n",
    "plt.plot(x_coarse, h_sampled[0], label=\"t = 1e-6\")\n",
    "plt.plot(x_coarse, h_sampled[1], label=\"t = 1e-5\")\n",
    "plt.plot(x_coarse, h_sampled[2], label=\"t = 1e-4\")\n",
    "plt.plot(x_coarse, h_sampled[3], label=\"t = 1e-3\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$h_\\epsilon(x, t), \\ \\epsilon=10^{-14}$\")\n",
    "#plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.savefig(\"sim_results_eds_coarse.png\", dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51b2ba",
   "metadata": {},
   "source": [
    "## Fine-grid simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17977f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "\n",
    "# This is important! dx = dom_length / N\n",
    "dx = float(2/N)\n",
    "\n",
    "dt = float(1e-7)\n",
    "eps = float(1e-14)\n",
    "\n",
    "x_fine = jnp.linspace(-1.0, 1.0, N, endpoint=False, dtype=jnp.float64, device=cpu)\n",
    "\n",
    "h0_fine = 0.8 - jnp.cos(jnp.pi * x_fine) + 0.25 * jnp.cos(2 * jnp.pi * x_fine)\n",
    "\n",
    "# Need to make sure h0_coarse lives on cpu\n",
    "h0_fine = jax.device_put(h0_fine, cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb23103",
   "metadata": {},
   "source": [
    "### Solution evolution using the generic scheme with large $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10000\n",
    "h_curr = h0_fine\n",
    "\n",
    "h_min = jnp.min(jnp.abs(h_curr))\n",
    "\n",
    "sampled_iters = jnp.array([9, 99, 999, 9999])\n",
    "\n",
    "h_sampled = []\n",
    "\n",
    "for k in range(K):\n",
    "\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"Iter {k}\")\n",
    "\n",
    "\n",
    "    F = lambda h: GS(h, h_curr, dx, dt, eps)\n",
    "\n",
    "    h_next = newton(F, h_curr, rtol=1e-8, atol=2e-10, max_iter=50, curr_step=k+1, prev_min=h_min)\n",
    "\n",
    "    h_min = jnp.min(jnp.abs(h_curr))\n",
    "    h_curr = h_next\n",
    "\n",
    "    if k in sampled_iters:\n",
    "        h_sampled.append(h_curr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f274246",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_fine, h0_fine, label=\"t = 0\")\n",
    "plt.plot(x_fine, h_sampled[0], label=\"t = 1e-6\")\n",
    "plt.plot(x_fine, h_sampled[1], label=\"t = 1e-5\")\n",
    "#plt.plot(x_coarse, h_curr, label=\"t = 4.92e-5\")\n",
    "plt.plot(x_fine, h_sampled[2], label=\"t = 1e-4\")\n",
    "plt.plot(x_fine, h_sampled[3], label=\"t = 1e-3\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$h_\\epsilon(x, t), \\ \\epsilon=10^{-11}$\")\n",
    "#plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.savefig(\"sim_results_generic_coarse.png\", dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_fine[512:540], h_curr[512:540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fe540",
   "metadata": {},
   "outputs": [],
   "source": [
    "newton(F, h_curr, rtol=1e-8, atol=2e-10, max_iter=50, curr_step=k+1, prev_min=h_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a70320",
   "metadata": {},
   "source": [
    "### Solution evolution using the entropy-dissipating scheme with large $\\Delta t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10000\n",
    "h_curr = h0_coarse\n",
    "\n",
    "h_min = jnp.min(jnp.abs(h_curr))\n",
    "\n",
    "sampled_iters = jnp.array([9, 99, 999, 9999])\n",
    "\n",
    "h_sampled = []\n",
    "\n",
    "for k in range(K):\n",
    "\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"Iter {k}\")\n",
    "\n",
    "\n",
    "    F = lambda h: EDS(h, h_curr, dx, dt, eps)\n",
    "\n",
    "    h_next = newton(F, h_curr, rtol=1e-8, atol=1e-10, curr_step=k+1, prev_min=h_min)\n",
    "\n",
    "    h_min = jnp.min(jnp.abs(h_curr))\n",
    "    h_curr = h_next\n",
    "\n",
    "    if k in sampled_iters:\n",
    "        h_sampled.append(h_curr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_coarse, h0_coarse, label=\"t = 0\")\n",
    "plt.plot(x_coarse, h_sampled[0], label=\"t = 1e-6\")\n",
    "plt.plot(x_coarse, h_sampled[1], label=\"t = 1e-5\")\n",
    "plt.plot(x_coarse, h_sampled[2], label=\"t = 1e-4\")\n",
    "plt.plot(x_coarse, h_sampled[3], label=\"t = 1e-3\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$h_\\epsilon(x, t), \\ \\epsilon=10^{-11}$\")\n",
    "#plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.savefig(\"sim_results_eds_coarse.png\", dpi = 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-metal",
   "language": "python",
   "name": "jax-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
